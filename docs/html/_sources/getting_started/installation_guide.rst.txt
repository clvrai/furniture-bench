Installation Guide
=========================================================
This document provides a step-by-step installation guide of our real-world environment, including both hardware and software setups.

.. |br| raw:: html

  <br/>

Requirements
~~~~~~~~~~~~~~~~~

.. prerequisites::
    Shopping List üõí

    - ü§ñ Franka Emika Panda `(link) <https://www.franka.de/>`__ and bench clamp `(link) <https://download.franka.de/Bench_Clamp.pdf>`__
    - 3x Intel RealSense D435 `(link) <https://store.intelrealsense.com/buy-intel-realsense-depth-camera-d435.html>`__
    - Option 1 [#f1]_:
        - 1x Manfrotto Variable Friction Arm with Camera Bracket `(link) <https://www.manfrotto.com/us-en/photo-variable-friction-arm-with-bracket-244/>`__
        - 1x Manfrotto Super Clamp `(link) <https://www.manfrotto.com/global/super-clamp-w-lt-stud-1-4-2900-035rl/>`__
        - 1x Ulanzi ULS01 camera mount `(link) <https://www.amazon.com/Flexible-Adjustable-Articulated-Rotatable-Aluminum/dp/B08LV7GZVB?th=1>`__
    - Option 2:
        - 2x Manfrotto Variable Friction Arm with Camera Bracket `(link) <https://www.manfrotto.com/us-en/photo-variable-friction-arm-with-bracket-244/>`__
        - 2x Manfrotto Super Clamp `(link) <https://www.manfrotto.com/global/super-clamp-w-lt-stud-1-4-2900-035rl/>`__
    - Black IKEA TOMMARYD table `(link) <https://www.ikea.com/us/en/p/tommaryd-table-anthracite-s99304804/>`__
    - Background frame (larger than w x h: 190 cm x 150 cm)
    - 2x tripod (extends longer than 1.2 m in height)
    - Green photography backdrop (comparable to w x h: 280 cm x 400 cm for wide-angle coverage)
    - 1x LED light panel supporting color temperature (4600 K-6000 K) and brightness (4000 lm)
    - 4x 10 feet USB Type-C to Type-A 3.1 cables `(link) <https://www.amazon.com/AmazonBasics-Double-Braided-Nylon-Type-C/dp/B07D7NNJ61>`__
    - üñ•Ô∏è Server computer (an 8th gen i7 or AMD Ryzen 5 5600X processors, or better)
    - üñ•Ô∏è Client computer (an Intel 8th generation i7 or AMD Ryzen 5 5600X processor, four USB 3 Type-A ports with high bandwidth, and a NVIDIA RTX 3070 GPU, or better)
    - Oculus Quest 2 (optional for data collection) `(link) <https://store.facebook.com/quest/products/quest-2/>`__
    - 3D printer
    - White PLA 3D printer filament (density of 1.27 g/cm^3)
    - Double-sided rubber tape
    - Any keyboard and mouse
    - 1x plastic ruler and 1x tape ruler
    - 2x M3x10mm hex socket screw `(link) <https://www.amazon.com/uxcell-M3x8mm-Socket-Button-Screws/dp/B09Q5TVS74/ref=sxin_16_pa_sp_search_thematic_sspa?content-id=amzn1.sym.c8697a08-4071-4b95-a6c6-18057bcdb898%3Aamzn1.sym.c8697a08-4071-4b95-a6c6-18057bcdb898&cv_ct_cx=M3%2B8mm%2Bhex%2Bbolt&keywords=M3%2B8mm%2Bhex%2Bbolt&pd_rd_i=B09Q5WRF7N&pd_rd_r=bd689c38-aa13-4aec-9016-cfdc73dced40&pd_rd_w=9cgO6&pd_rd_wg=bnHIa&pf_rd_p=c8697a08-4071-4b95-a6c6-18057bcdb898&pf_rd_r=9JX1GNW28TQPA1Z6WE04&qid=1683097199&s=books&sbo=RZvfv%2F%2FHxDF%2BO5021pAnSA%3D%3D&sr=1-2-364cf978-ce2a-480a-9bb0-bdb96faa0f61-spons&spLa=ZW5jcnlwdGVkUXVhbGlmaWVyPUEzUzMzSlVKWU8yMUxQJmVuY3J5cHRlZElkPUEwNjU2NzE2Mkw2QUNGQllZU0NUMiZlbmNyeXB0ZWRBZElkPUEwODMxMDk4MzVJOUxSTTRFU1kwNiZ3aWRnZXROYW1lPXNwX3NlYXJjaF90aGVtYXRpYyZhY3Rpb249Y2xpY2tSZWRpcmVjdCZkb05vdExvZ0NsaWNrPXRydWU&th=1>`__
    - 1x M6x25mm hex socket screw `(link) <https://www.amazon.com/uxcell-M6x25mm-Socket-Button-Screws/dp/B09MSZKHS1/ref=sxin_16_pa_sp_search_thematic_sspa?content-id=amzn1.sym.c8697a08-4071-4b95-a6c6-18057bcdb898%3Aamzn1.sym.c8697a08-4071-4b95-a6c6-18057bcdb898&crid=3IO512FWR50ET&cv_ct_cx=M6x25mm%2BHex%2BSocket&keywords=M6x25mm%2BHex%2BSocket&pd_rd_i=B09MSZKHS1&pd_rd_r=95281393-c1d8-4c70-b09b-bd92a1be0843&pd_rd_w=kgv3I&pd_rd_wg=0CZpf&pf_rd_p=c8697a08-4071-4b95-a6c6-18057bcdb898&pf_rd_r=V7G2NMKYC8PF2Q22MARR&qid=1683097644&s=books&sbo=RZvfv%2F%2FHxDF%2BO5021pAnSA%3D%3D&sprefix=m6x25mm%2Bhex%2Bsocket%2Cstripbooks-intl-ship%2C231&sr=1-1-364cf978-ce2a-480a-9bb0-bdb96faa0f61-spons&spLa=ZW5jcnlwdGVkUXVhbGlmaWVyPUEyWjlNSTUwNTlONEVIJmVuY3J5cHRlZElkPUEwMzk0NjM3M1ZONFNGWTFCWjhCNyZlbmNyeXB0ZWRBZElkPUEwMTY4MjQ0MzMzTTFVWTRMTUxGUiZ3aWRnZXROYW1lPXNwX3NlYXJjaF90aGVtYXRpYyZhY3Rpb249Y2xpY2tSZWRpcmVjdCZkb05vdExvZ0NsaWNrPXRydWU&th=1>`__

    **Prerequisites**

    - üìñ Franka Panda system `Franka Control Interface (FCI) version == 4.2.2. <https://frankaemika.github.io/docs/libfranka_changelog.html#id1>`__

    - Client computer
        -  üõ†Ô∏è Ubuntu 20.04LTS PC, with CUDA driver available
        -  üìñ `Docker <https://docs.docker.com/engine/install/ubuntu/>`__
        -  üìñ `nvidia-docker2 <https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#installing-on-ubuntu-and-debian>`__
    - Server computer
        -  üõ†Ô∏è Ubuntu 20.04LTS PC, `real-time kernel <https://frankaemika.github.io/docs/installation_linux.html#setting-up-the-real-time-kernel>`__ installed.
        -  üìñ `Docker <https://docs.docker.com/engine/install/ubuntu/>`__

Print 3D Furniture Model ü™ë
~~~~~~~~~~~~~~~~~~~~~~~~~~

Printing 3D furniture models, obstacles, and a camera mount of our FurnitureBench will take a long time (10-23 hours).
We recommend to 3D print the models before start installing the robot environment


- Download STL files you want to experiment with from `3D model Google Drive <https://drive.google.com/drive/folders/1Boj7pyNWklOUVA0ByO0d-J7DM7xfFfRg?usp=sharing>`__.
- Slice the STL file and add support structures using a 3D printer software. We used `FlashPrint <https://www.flashforge.com/product-detail/FlashPrint-slicer-for-flashforge-fdm-3d-printers>`__ *fast* option, PLA filament for the printing.
- Refer to :ref:`3D Printing üñ®Ô∏è` to learn more about 3D printing.

Attach AprilTag to the Furniture
~~~~~~~~

-  Print AprilTags in `A4 <https://drive.google.com/file/d/11wwA3IrXjIVSwVy1sp0hLcB8-J_9rAxJ/view?usp=sharing>`__ or `letter <https://drive.google.com/file/d/1eIG3YspcSumtT-o9NvtCvUtRDWPW5hhU/view?usp=sharing>`__ size. Do **NOT** change the aspect ratio and scale.
-  Attach AprilTags to the furniture parts. A furniture part has a placeholder with an ID of its corresponding AprilTag.

.. checklist::

    Attach AprilTags such that they are oriented correctly:

    -  When cutting the tags from the printed paper, ensure that the printed paper is oriented correctly: you can read the words and numbers from left to right and top to bottom.
    -  Before attaching the tag to the furniture piece, do NOT change the orientation of the AprilTag from what it was when you cut it out.
    -  As you attach the tag, ensure that the number on the corresponding furniture piece is also oriented correctly: the number is readable left to right.

    Use the below example as a sanity check to make sure you understand:

    .. |image1| image:: ../_static/images/tag10.jpg
        :width: 130px
        :height: 130px
    .. |image2| image:: ../_static/images/correct_attach.jpg
        :width: 130px
        :height: 180px
    .. |image3| image:: ../_static/images/wrong_attach.jpg
        :width: 130px
        :height: 180px

    +-----------------------------------+--------------------------+-------------------------------------------+
    | |image1|                          |            |image2|      |         |image3|                          |
    +===================================+==========================+===========================================+
    | \(a) Tag: square_table leg1 (10)  |  \(b) Correct            |  \(c) Wrong                               |
    +-----------------------------------+--------------------------+-------------------------------------------+

Mount Robot on Table
~~~~~~~~~~~~~~~~~~~~~~
The first step is mounting the robot on the table. To ensure the precise placement of the robot, follow the step-by-step
instructions

-  As shown in (a), attach marking tapes to the robot body to specify its center. Make sure that the tape's left edge is in the center of the triangle sticker and the tape is attached straight by looking at it from the front view.
-  Align one ruler so that 0 cm is at the left edge of the table and extend it straight, as shown in (b).
-  Place the robot strictly at point 34.5 cm of the ruler. Especially, match the center of the robot indicated by the left edge of the tape, as shown in (c).
-  Make sure the robot is tightly attached to the side of the table, with no room left between it and the table. To double-check, make sure that both rear support pads are closely pressed against the edge of the table and that there is no space left in between, as shown in (d).
-  Firmly attach the robot to the table by tightly screwing the robot mount, as shown in (e).
-  Remove the affixed tape from the robot once this step is completed.

.. |table_image1| image:: ../_static/instruction/center_of_robot_base.jpg
.. |table_image2| image:: ../_static/instruction/robot_placement_ruler.jpg
.. |table_image3| image:: ../_static/instruction/robot_base.jpg
.. |table_image4| image:: ../_static/instruction/robot_mount.jpg
.. |table_image5| image:: ../_static/instruction/firm_screw.jpg

.. table::
    :widths: 20 20 20 20 20

    +---------------------------+----------------------+------------------------------+----------------------------------------------------------------------+-------------------------+
    |      |table_image1|       |    |table_image2|    |        |table_image3|        |                            |table_image4|                            |     |table_image5|      |
    +===========================+======================+==============================+======================================================================+=========================+
    | \(a) Center of the robot  | \(b) Ruler on table  | \(c) Robot position on table | \(d) Bottom-up view. Two rear supports are indicated by blue circles | \(e) Screwing the mount |
    +---------------------------+----------------------+------------------------------+----------------------------------------------------------------------+-------------------------+

.. Checklist::

    - Make sure the robot is installed at 34.5 cm off from the left edge of the table.
    - The robot should be tightly attached to the table without margin.
    - The robot mount is tightly screwed.

Install Background
~~~~~~~~~~~~~~~~~~

.. image:: ../_static/instruction/background.jpg
    :width: 40%
    :align: right
    :alt: background

.. |background_image1| image:: ../_static/instruction/background_left_clamp.jpg
.. |background_image2| image:: ../_static/instruction/background_right_clamp.jpg
.. |background_image3| image:: ../_static/instruction/background_left_pole.jpg
.. |background_image4| image:: ../_static/instruction/background_left_pole_covered.jpg

For consistent background across different lab environments, cover the background
with a green backdrop.

- Clamp the left side of the backdrop, as shown in (a). Be sure to leave some extra cloth to ensure coverage of the left side as well.
- Similarly, clamp the right side of the backdrop, as shown in (b).
- Place a tripod next to the table, and hang the left side of the backdrop to the tripod, as shown in (c) and (d).
- Repeat this process for the right side.
- Eventually, The background should look like figure on the right.

.. table::
    :widths: 25 25 25 25

    +----------------------------+-----------------------------+---------------------+------------------------+
    |    |background_image1|     |     |background_image2|     | |background_image3| |  |background_image4|   |
    +============================+=============================+=====================+========================+
    | \(a) Background left clamp | \(b) Background right clamp |   \(c) Left pole    | \(d) Left pole covered |
    +----------------------------+-----------------------------+---------------------+------------------------+


.. Checklist::

    - Make sure there are minimum wrinkles and shadows on the cloth.
    - Green cloth fully covers the narrow side of the table.
    - Green cloth covers the left and right edge of the table (at least 1/3 of length) so that the cameras are not disturbed by background noise.

Install Base AprilTag
~~~~~~~~~~~~~~~~~~~~~

The base AprilTag defines the world coordinate system; therefore, the camera will be set relative to this base tag. The position and angle of the base tag are critical for reproducibility; thus the placement of the base tag on the table should be precise.
Be cautious when attaching the AprilTag, as it can easily be attached with tilted angles. Ensure that both the rulers and AprilTag are properly aligned and straight.

- Align tape ruler so that 0 cm is at the left of the table and plastic ruler so that 0 cm is at the top edge of the table, as illustrated in (a).
- Place the center of the base tag at 24.5 cm horizontally and 37.5 cm vertically, as shown in (b). Make sure the two rulers are perpendicular.
- Check the direction of the base tag by observing its pattern: correct direction in (c).
- Use double-sided tape to affix the base tag. Note that wrinkled paper causes unreliable detection. Ensure the paper remains flat by attaching it with double-sided tape in all four corners.
.. |base_apriltag_ruler| image:: ../_static/instruction/base_apriltag_bird.jpg
.. |base_apriltag_coordinate| image:: ../_static/instruction/base_apriltag.jpg
.. |base_apriltag_placement| image:: ../_static/instruction/correct_base_dir.jpg
.. |base_apriltag_example| image:: ../_static/instruction/wrong_base_dir.jpg


.. table::
    :widths: 25 25 25 25

    +--------------------------------------+---------------------------------------+-----------------------------------+-------------------------------------------------+
    | |base_apriltag_ruler|                |    |base_apriltag_coordinate|         | |base_apriltag_placement|         | |base_apriltag_example|                         |
    +======================================+=======================================+===================================+=================================================+
    | \(a) Rulers on table                 | \(b) Base tag position on table       | \(c) Correct base tag direction   | \(d) Wrong base tag diretion                    |
    +--------------------------------------+---------------------------------------+-----------------------------------+-------------------------------------------------+

.. checklist::

    - Double-check the base AprilTag in the exact position (like, less than 2 mm error).
    - The base AprilTag is firmly attached flat without wrinkles.
    - Check the pattern of the base tag to ensure its correct direction.

Install Front and Rear Cameras
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. .. image:: ../_static/instruction/camera_serial.jpg
..     :width: 30%
..     :align: right
..     :alt: camera_serial

.. |camera_serial| image:: ../_static/instruction/camera_serial.jpg
    :scale: 15
.. |camera_serial_realsense_viewer| image:: ../_static/instruction/serial_realsense_viewer.jpg
    :scale: 15

Our system requires three cameras: front, rear, and wrist cameras. Prior to installation, determine
the specific camera to be used for each view, and write down the serial numbers of the cameras
for each wrist, front, and rear camera, as they will be required for subsequent connections.
A camera serial number can be found in (a) a label on the camera bottom, and (b) `realsense-viewer <https://github.com/IntelRealSense/librealsense/blob/master/doc/distribution_linux.md>`__ software.

.. table::
    :widths: 15 15

    +--------------------------------------------------------+----------------------------------------+
    | |camera_serial|                                        | |camera_serial_realsense_viewer|       |
    +========================================================+========================================+
    | \(a) Serial number written on the bottom of the camera | \(b) Serial number in realsense-viewer |
    +--------------------------------------------------------+----------------------------------------+

.. .. image:: ../../_static/images/serial.jpg
..     :width: 20%
..     :align: right
..     :alt: serial_realsense_viewer


First, install the front and rear cameras. You can utilize any camera mount product for the front
camera mount if they follow the instructions and match the camera views. We do, however, highly
recommend users opt for a camera mount from either Ulanzi or Manfrotto, both of which we have
confirmed to be reliable. In this context, we provide a guide on how to install these specific mounts,
although you have the flexibility to adjust it during fine-grained calibration in a later section.

.. |front_camera_position| image:: ../_static/instruction/front_camera_position.jpg
.. |front_camera_distance| image:: ../_static/instruction/front_camera_distance.jpg
.. |front_camera_firmly_attached| image:: ../_static/instruction/front_camera_firmly_attached.jpg

.. |manfrotto_front_camera_position| image:: ../_static/instruction/manfrotto_front_camera_position.jpg
.. |manfrotto_front_camera_distance| image:: ../_static/instruction/manfrotto_front_camera_distance.jpg
.. |manfrotto_front_camera_firmly_attached| image:: ../_static/instruction/manfrotto_front_camera_firmly_attached.jpg

- **Option 1, Ulanzi:** Clamp the front camera mount to the right side of the table, as shown in (1-a). Position the camera mount 8 cm away from the table edge, as shown in (1-b). While measuring the distance, ensure the camera mount's base is firmly attached, as illustrated in (1-c).

    .. table::
        :widths: 30 30 30

        +------------------------------+------------------------------+--------------------------------+
        | |front_camera_position|      | |front_camera_distance|      | |front_camera_firmly_attached| |
        +==============================+==============================+================================+
        | \(1-a) Front camera position | \(1-b) Front camera distance | \(1-c) Attachment              |
        +------------------------------+------------------------------+--------------------------------+

- **Option 2, Manfrotto:** Clamp the front camera mount to the right side of the table. The camera bracket needs to be affixed using the left hole and the locking wheel should be oriented outward, as shown in (2-a). Position the camera mount 7 cm away from the table edge, as shown in (2-b).  Arrange the deeper section to face the inside to provide better flexibility in camera movement. During the distance measurement, make sure that the camera mount's base is firmly attached and valves are securely fastened, as shown in (2-c).

    .. table::
        :widths: 30 30 30

        +-----------------------------------+-----------------------------------+------------------------------------------+
        | |manfrotto_front_camera_position| | |manfrotto_front_camera_distance| | |manfrotto_front_camera_firmly_attached| |
        +===================================+===================================+==========================================+
        | \(2-a) Front camera position      | \(2-b) Front camera distance      | \(2-c) Attachment                        |
        +-----------------------------------+-----------------------------------+------------------------------------------+

- Place the camera approximately in the center (horizontally) of the table and orient it to face the base AprilTag. You will fine-tune its pose in a later section.
- Connect the front camera to client computer using a USB 3.1 cable.
- Clamp the rear camera mount next to the robot base, as shown in (d). Plug USB 3.1 cable. Utilize a cable tie to fasten the pair of cables from the robot and the single cable from the camera. Ensure a sufficient gap between the camera mount and the robot to avoid any collision.

.. figure:: ../_static/instruction/rear_camera_installation.jpg
    :width: 60%
    :alt: rear_camera

    \(d) Rear camera installation.

Install Wrist Camera
~~~~~~~~~~~~~~~~~~~~
Now, we install the wrist camera as follows:

- Install the wrist camera on the robot wrist using the 3D printed camera mount. Take note of the direction in which the RGB camera (represented with yellow circles) should face: it should be aimed toward the gripper's tip, as shown in (b). The camera should be positioned on the rear side of the end-effector. Take a look at (c) and (d) to gain a clear understanding of its placement.
- Connect the wrist camera to client computer using a USB 3.1 cable.
- Fasten the cable to the robot arm with three cable ties, as shown in (d). Ensure to provide additional slack in the cable, allowing the robot to move without any tension from the cable. Trim the surplus length from the cable ties to ensure no extra material remains.

.. |camera_mount_screw| image:: ../_static/instruction/camera_nuts.jpg
.. |wrist_camera| image:: ../_static/instruction/camera_down_view.jpg
.. |wrist_camera2| image:: ../_static/instruction/wrist_position.jpg
.. |wrist_camera_cable| image::

.. table::
    :widths: 25 25 25

    +--------------------------------+-------------------+---------------------+
    | |camera_mount_screw|           | |wrist_camera|    | |wrist_camera2|     |
    +================================+===================+=====================+
    | \(a) Camera, mount, and screws | \(b) Wrist camera | \(c) Wrist camera   |
    +--------------------------------+-------------------+---------------------+

.. figure:: ../_static/instruction/cable_tie.jpg
    :width: 60%
    :alt: cable_organization

    \(d) Cable organization

.. checklist::

    - Ensure the direction of the wrist camera is correctly set; camera is positioned on end-effector's back side, and the cable is plugged to the left when viewed from the rear.  Firmly attach the camera and camera mount to the robot by tightening the screws.
    - Three cable ties are fastened as shown in (d).
    - The cable has additional slack.
    - The surplus length from the cable ties is trimmed.

Install Software
~~~~~~~~~~~~~~~~~~~~
We install our software stack using Docker due to complex dependencies and customized packages for our setup (e.g., forked `Polymetis <https://github.com/facebookresearch/fairo/tree/main/polymetis>`__).

Install Client
-----------------------------------------------
The Docker image is used for data collection, training, inference, and simulation. The image is built upon the ``nvidia/cuda:11.7.1-cudnn8-devel-ubuntu20.04``.
To make a use of it, your machine must have a CUDA driver installed (we've tested it with 515.105.01). Please refer to the provided link for details about the `compatibility of CUDA with different driver versions <https://docs.nvidia.com/deploy/cuda-compatibility/index.html#deployment-consideration-forward>`__.

The CPU-only version is available at :ref:`Install Client (CPU-only)`.

Here are the steps to install the software for client:

First, clone the repository and cd into it.

.. code:: bash

    # Clone the repository and cd into it
    git clone https://github.com/clvrai/furniture-bench.git
    cd furniture-bench

There are two ways to build client Docker image:

- Pull a pre-built Docker image from Docker Hub.

  .. code:: bash

    # Pull a pre-built docker image from Docker Hub
    docker pull furniturebench/client-gpu:latest
- Or build the Docker image yourself.

  .. code:: bash

    # Build the Docker image
    DOCKER_BUILDKIT=1 docker build -t client-gpu . -f docker/client_gpu.Dockerfile

.. tip::
    We clone the furniture-bench repository in order to mount it into the Docker image. This allows us to edit the code on the host machine and changes are applied to the Docker image as well.

Install Server
----------------

The server computer needs a real-time kernel and high-speed CPU (e.g., at least Intel i7 8th generation or AMD Ryzen 5 5600X CPU) for high frequency robot control of a Franka Panda arm.

Here are the steps to install the software for server:

.. code:: bash

   # Clone the furniture repository
   # (Same as Install Client)
   git clone https://github.com/clvrai/furniture-bench.git

   # Pull a pre-built docker image from Docker Hub
   docker pull furniturebench/server:latest

   # Or build the server Docker image yourself
   DOCKER_BUILDKIT=1 docker build -t server . -f docker/server.Dockerfile

Run Client
~~~~~~~~~~~~~~~~~~~~~~

1. Set up the environment variables. Consider storing variables in ``.bashrc`` or ``.zshrc`` so that you don't have to set them every time.

  .. code:: bash

    # (Optional) Environment variable for extra mounting (e.g., for data collection)
    # This will set Docker Volume flag -v $HOST_DATA_MOUNT:$CONTAINER_DATA_MOUNT
    export HOST_DATA_MOUNT=<path to host>
    export HOST_DATA_MOUNT=/hdd      # e.g., /hdd

    export CONTAINER_DATA_MOUNT=<path to container>
    export CONTAINER_DATA_MOUNT=/hdd # e.g., /hdd

    # Set absolute path to the furniture-bench repo
    export FURNITURE_BENCH=</path/to/furniture-bench>

    # (Optional) IsaacGym absolute path if you want to use the simulator
    export ISAAC_GYM_PATH=</path/to/isaacgym> # path to isaacgym downloaded from https://developer.nvidia.com/isaac-gym

2. Run client image. ``launch_client.sh`` will read the environment variables and run the Docker image.

  .. code:: bash

    # To show display in Docker container
    xhost +

    # make launch_client.sh executable.
    chmod +x launch_client.sh

    # In order to run the client image, you need to specify the option (--gpu, --cpu, --sim-gpu) and the image type (--built or --pulled).
    # E.g., GPU image + local built
    ./launch_client.sh --gpu --built

    # CPU image + pulled from Docker Hub
    ./launch_client.sh --cpu --pulled

    # E.g., GPU image with sim + pulled from Docker Hub
    ./launch_client.sh --sim-gpu --pulled

.. tip::

    - The \--gpu and \--sim-gpu options share the same underlying Docker image. The only difference between them is that the \--sim-gpu option verifies whether the isaacgym is properly installed and path is correctly set. If not, an error message will be displayed and the program will be terminated.
    - If you'd like to use a Docker image other than \--pulled or \--built, you can specify the image name using ``CLIENT_DOCKER`` environment variable. For example, ``export CLIENT_DOCKER=custom-built``. Once set, you execute launch_client.sh with a single argument, such as ``./launch_client.sh --gpu``. This command will internally read the environment variable and run the ``custom-built`` Docker image.

Set Up Connection
~~~~~~~~~~~~~~~~

.. image:: ../../_static/instruction/example_network_setup.jpg
    :width: 50%
    :align: right
    :alt: example_network_setup

Server, client, and robot communicate through a local Ethernet network, as shown in the figure on the right.

To establish connections to server and cameras, the following environment variables need to be set in client container:

.. code-block:: bash

    export SERVER_IP=<IP of Server computer> # e.g., 192.168.0.138
    export CAM_WRIST_SERIAL=<serial number of the wrist camera>
    export CAM_FRONT_SERIAL=<serial number of the front camera>
    export CAM_REAR_SERIAL=<serial number of the rear camera>

Now, ensure that all the cameras are correctly installed and appropriately connected. Execute the following command and confirm the items in the checklist.

.. code-block:: bash

    cd /furniture-bench
    python furniture_bench/scripts/run_cam_april.py

.. figure:: ../_static/instruction/image_view.jpg
    :width: 80%
    :align: center
    :alt: image_view

    \(a) Camera observations

.. checklist::

    - Ensure that the camera displays the wrist, front, and rear views in left-to-right order, as shown in (a).
    - The wrist camera view must observe both gripper tips as shown in the left image.
    - The rear camera should be able to detect the two markers present on the base tag, as shown in the right image.

Run Server
~~~~~~~~~~~~~~~~~~~~~~

To operate the robot, you need to activate FCI (Franka Control Interface) and launch a server-side daemon as explained below:

Access the control interface website.

1. Unlock the robot in the Franka Emika web interface, as shown in (a).
2. Release the activation button, as shown in (b). The light on the robot base should turn blue after releasing the button.
3. Activate FCI in the web interface, as shown in (c).

.. |unlock| image:: ../_static/instruction/unlock.jpg
.. |release_activation| image:: ../_static/instruction/release_activation.png
.. |activate_FCI| image:: ../_static/instruction/activate_FCI.jpg

.. table::
    :widths: 30 30 30

    +-------------+-------------------------+-------------------+
    | |unlock|    | |release_activation|    | |activate_FCI|    |
    +=============+=========================+===================+
    | \(a) Unlock | \(b) release activation | \(c) activate FCI |
    +-------------+-------------------------+-------------------+

And then launch a server-side daemon.

1. Launch the server Docker image

  .. code:: bash

    # Set path to the furniture-bench repository.
    # Consider storing in ``.bashrc`` or ``.zshrc`` for persistent settings.
    export FURNITURE_BENCH=</path/to/furniture-bench> # e.g. /home/<username>/furniture-bench

    # Run Docker image
    ./launch_server.sh --pulled # (case 1) Docker pull.
    ./launch_server.sh --built  # (case 2) Local build.

2. Set environment variables in server Docker container

  .. code:: bash

    # Set environment variables.
    # Note to specify IP of Franka Control (shop floor network), not IP of the Robot arm.
    export ROBOT_IP=<ip.of.the.robot.controller> # e.g., 192.168.0.10

3. Launch the server daemon.
  .. code:: bash

    # Launch the arm and gripper daemon together.
    /furniture-bench/launch_daemon.sh

    # Or run the arm and gripper daemon separately.
    # Arm daemon
    launch_robot.py robot_client=franka_hardware robot_client.executable_cfg.robot_ip=$ROBOT_IP
    # Gripper daemon
    launch_gripper.py gripper=franka_hand gripper.cfg.robot_ip=$ROBOT_IP

.. tip::

    Note that the only program that needs to be run on the server side is the *daemon*.
    Other programs, such as the camera setup, policy training, and data collection, are all run on the client side.

Test Software Setup
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Execute python furniture_bench/scripts/reset.py in a terminal on client side and see the robot moves
to the reset pose.

.. code::

    python furniture_bench/scripts/reset.py

Fine-tune Front Camera Pose
~~~~~~~~~~~~~~~~~~~~~~~~~~~~
We provide a visualization tool to help calibrate the front camera pose with the pre-recorded view overlaid on top of the current camera view. The calibration can be achieved by matching the numbers and images shown in our calibration tool.

.. image:: ../_static/instruction/coordinate.jpg
    :width: 40%
    :align: right
    :alt: coordinate

In visualization tool, the image from the current view is displayed as a solid layer, while the reference image you need to match appears transparent. The number indicates the deviation of the current camera poses from the desired pose. The red texts indicate that the deviation exceeds the threshold (¬±0.004 for the position (pos), ¬±0.8 for the rotation (rot)), whereas green texts represent that it is within acceptable the boundary. Refer to the figure on the right for a better understanding of the coordinate system to adjust the camera pose

- First, run the following command to move the robot up to prevent it from blocking the camera's view.

  .. code::

    python furniture_bench/scripts/move_up.py
- Run the camera calibration tool:

  .. code::

    python furniture_bench/scripts/calibration.py --target setup_front

- Adjust the camera to **match both images and numbers**.
- Here we list *tips* to simplify the process of matching the camera pose.
    - For the Ulanzi camera mount, first adjust the height of the camera mount to match the z position, and then fasten it in place.
    - When dealing with the Manfrotto camera mount, prioritize matching all settings except for the x position, given that it can be independently modified using the camera bracket.
    - In the beginning, ignore the numbers and focus on aligning the table outline and robot base (using the two holes in the robot base as reference points). Take a look at how the matched image looks like in (a).
    - Iterative adjust position and rotation to match the alignment and numbers. Based on our experience, it was simpler first to align the position and then adjust the rotation minutely for best alignment


.. |setup_fromt_calibrated| image:: ../../_static/instruction/setup_front_calibrated.jpg
.. |setup_fromt_number_match_image_mismatch| image:: ../../_static/instruction/setup_front_number_match_image_mismatch.jpg
.. |setup_front_number_mismatch_image_match| image:: ../../_static/instruction/setup_front_number_mismatch_image_match.jpg

.. table::
    :widths: 30 30 30

    +-------------------------------------+--------------------------------------------+--------------------------------------------+
    | |setup_fromt_calibrated|            | |setup_fromt_number_match_image_mismatch|  | |setup_front_number_mismatch_image_match|  |
    +=====================================+============================================+============================================+
    | \(a) Numbers and image match        | \(b) Number match, image mismatch          | \(c) image match, number mismatch          |
    +-------------------------------------+--------------------------------------------+--------------------------------------------+

.. checklist::

    - All numbers on the screen should turn green.
    - The boundary of the table and the base AprilTag must be aligned with the pre-recorded image.
    - The position of the robot base (i.e., two holes) should exactly match the pre-recorded image.


Install Obstacle
~~~~~~~~~~~~~~~~
The 3D printed obstacle can be attached to the table using double-sided rubber tape. The exact pose of the obstacle can be viewed using our calibration tool, as shown in the figure below.

- Install the obstacle with the guidance of the provided visualization tool:

  .. code-block:: bash

    python furniture_bench/scripts/calibration.py --target obstacle

- Attach the obstacle to the table while aligning it with the pre-recorded obstacle pose.

    .. figure:: ../_static/instruction/obstacle.jpg
        :width: 80%
        :align: center
        :alt: obstacle

        \(a) Obstacle installation.

- Affix the obstacle with double-sided rubber tape, as shown in the figure below. Make sure the obstacle does not move when pushed.

    .. figure:: ../_static/instruction/obstacle_affix.jpg
        :width: 80%
        :align: center
        :alt: obstacle

        \(b) Affix obstacle. The red circles represent where to attach the double-sided rubber tape.

.. checklist::

    - Adjust the obstacle to identically match the transparent one in the visualization tool, as shown on the right figure of (a). There should be no discrepancy.
    - Firmly attach the obstacle using double-sided rubber tape to prevent it from moving when pushed.

Set Up Light
~~~~~~~~~~~

During the data collection process, we randomize the light temperature between 4600 K-6000 K as well as the intensity,
position, and direction of the light. On the other hand, during the evaluation process, it is essential to maintain lighting conditions
as similar as possible. In order to accomplish this, the light should be placed on the left side of the table as shown in :ref:`FurnitureBench Overview`.
Furthermore, the temperature range of 4600 K to 6000 K and the brightness range of 500 lm to 1000 lm should be set for the
lighting panel.

Test the Environment
~~~~~~~~~~~~~~~~~~~~

.. image:: ../_static/instruction/reproducibility_performance.jpg
    :width: 45%
    :align: right
    :alt: reproducibility_performance

| To verify if the environment setup is correctly done, test runs can be performed using a pre-trained policy for one leg assembly task. The evaluation results can be compared with the original environment, shown in the figure on the right.
|
|
The one-leg assembly consists of phases: (1) pick up the tabletop, (2) push to the corner, (3) pick up the leg, (4) insert the leg, and (5) screw the leg. The pre-trained policy should be able to achieve more than 3 phases on average with the 15-30% success rate on the full one-leg assembly task.

Before evaluation, make sure the following requirements are met:

.. checklist::

    -  Double-check the camera calibration using the following script. All the numbers should be green and the robot base, obstacle, and base tag should be aligned accurately

      .. code::

        python furniture_bench/scripts/calibration.py --target one_leg
    - Green backdrop cloth has minimum wrinkles.
    - Wipe three camera lenses using a lens cloth, as they may be blurry from fingerprint smudges.

Install requirements for the evaluation:

.. code::

    pip install -r implicit_q_learning/requirements.txt
    pip install -e r3m
    pip install -e vip

Place the furniture components randomly within the workspace, as shown in the figure below.

.. figure:: ../_static/instruction/furniture_placement.jpg
    :width: 60%
    :alt: initialization_GUI_prompt

    Furniture placement.

Evaluate the pre-trained policy using the following script:

.. code::

    ./evaluate.sh --low

.. .. figure:: ../_static/instruction/initialization_GUI_prompt.jpg
..     :width: 60%
..     :alt: initialization_GUI_prompt

The command above will first show visualization and prompt to indicate where furniture parts should be positioned. Initialize the furniture parts, as shown in (a). The screen will prompt ‚Äúinitialization done‚Äù when everything is correctly aligned, as shown in (b).

.. |init_GUI_prompt| image:: ../../_static/instruction/initialization_GUI_prompt.jpg
.. |init_done| image:: ../../_static/instruction/initialization_done.jpg

.. table::
    :widths: 30 30

    +-----------------------------------------------------------------------+----------------------------------------------------------------------------------+
    | |init_GUI_prompt|                                                     | |init_done|                                                                      |
    +=======================================================================+==================================================================================+
    | \(a) Visualization tool and prompt indicates where to place each part | \(b) Initialization done. After this stage, press ‚ÄùEnter‚Äù to execute the policy. |
    +-----------------------------------------------------------------------+----------------------------------------------------------------------------------+


Once the initialization is done, press ‚ÄúEnter‚Äù to execute the policy. Make sure there is nothing but furniture parts in the
workspace.

.. checklist::

    - The evaluation result should be matched with the pre-recorded result.
    - During execution, ensure that robot not collide with anything or itself.

.. rubric:: Footnotes

.. [#f1] Here we explain why we provide two options with the exception from the original paper. "We offer two distinct options for the camera mount, each depends on your choices for the front camera mount. Throughout our evaluations, we utilized Option 2. However, during subsequent user testing, we observed that some participants found Option 1 to be more intuitive to set up due to its ability to independently move the camera arm along different axes.  Both these options are detailed in our step-by-step setup guide."
